{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from itertools import chain\n",
    "\n",
    "import simple_pinn\n",
    "import utils\n",
    "import cv_mesh\n",
    "import cv_solver\n",
    "import athena_reader\n",
    "\n",
    "# for dev purposes, reload these modules each time this cell is run\n",
    "import importlib\n",
    "importlib.reload(simple_pinn)\n",
    "importlib.reload(utils)\n",
    "importlib.reload(cv_mesh)\n",
    "importlib.reload(cv_solver)\n",
    "importlib.reload(athena_reader)\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\" \n",
    "\n",
    "# torch.set_default_dtype(torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_domain = y_domain = [-10, 10]\n",
    "Nx_sample = Ny_sample = 100\n",
    "mesh = cv_mesh.CVMesh(\n",
    "    x_domain,\n",
    "    y_domain,\n",
    "    Nx_sample,\n",
    "    Ny_sample,\n",
    "    quad_pts=(8, 8),\n",
    "    quad_rule=\"composite_trapezoid\",\n",
    "    requires_grad=True,\n",
    ")\n",
    "mesh.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # The problem consists of an annulus of inner radius a and outer radius b, centered at the origin, with dielectric constant epsilon_1,\n",
    "# # immersed in a medium of dielectric constant epsilon_0; an external field of strength E_0 is applied in the positive x-direction.\n",
    "# a = 0.1\n",
    "# b = 5.0\n",
    "# epsilon_0 = 1.0\n",
    "# epsilon_1 = 5.0\n",
    "# # epsilon_0 = 5.0\n",
    "# # epsilon_1 = 1.0\n",
    "# E_0 = 1.0\n",
    "\n",
    "# # The functions below provide the correct electric potential and its derivatives, as well as some other helpful things.\n",
    "# # Note that all have a dummy \"eos=None\" argument, because the CV solver framework expects to pass around an equation of state.\n",
    "\n",
    "\n",
    "# # function that provides the correct electric potential for inputs (x, y)\n",
    "# def synthetic_data(inputs, eos=None):\n",
    "#     x = inputs[..., 0]\n",
    "#     y = inputs[..., 1]\n",
    "\n",
    "#     rho = torch.sqrt(x**2 + y**2)\n",
    "#     phi = torch.atan2(y, x)\n",
    "\n",
    "#     # Create conditions for the different regions\n",
    "#     condition1 = rho < a\n",
    "#     condition2 = (rho >= a) & (rho < b)\n",
    "#     condition3 = rho >= b\n",
    "\n",
    "#     # Initialize the potential tensor\n",
    "#     Phi = torch.zeros_like(rho)\n",
    "\n",
    "#     # Calculate Phi for rho < a\n",
    "#     Phi[condition1] = (\n",
    "#         (\n",
    "#             -4\n",
    "#             * b**2\n",
    "#             * epsilon_1\n",
    "#             * epsilon_0\n",
    "#             / (\n",
    "#                 (\n",
    "#                     b**2 * (epsilon_1 + epsilon_0) ** 2\n",
    "#                     - a**2 * (epsilon_1 - epsilon_0) ** 2\n",
    "#                 )\n",
    "#             )\n",
    "#         )\n",
    "#         * E_0\n",
    "#         * rho[condition1]\n",
    "#         * torch.cos(phi[condition1])\n",
    "#     )\n",
    "\n",
    "#     # Calculate Phi for a <= rho < b\n",
    "#     Phi[condition2] = (\n",
    "#         (\n",
    "#             -2\n",
    "#             * a\n",
    "#             * b**2\n",
    "#             * epsilon_0\n",
    "#             / (\n",
    "#                 (\n",
    "#                     b**2 * (epsilon_1 + epsilon_0) ** 2\n",
    "#                     - a**2 * (epsilon_1 - epsilon_0) ** 2\n",
    "#                 )\n",
    "#             )\n",
    "#         )\n",
    "#         * (\n",
    "#             (epsilon_1 + epsilon_0) * (rho[condition2] / a)\n",
    "#             + (epsilon_1 - epsilon_0) * (a / rho[condition2])\n",
    "#         )\n",
    "#         * E_0\n",
    "#         * torch.cos(phi[condition2])\n",
    "#     )\n",
    "\n",
    "#     # Calculate Phi for rho >= b\n",
    "#     Phi[condition3] = (\n",
    "#         (\n",
    "#             -rho[condition3]\n",
    "#             + (b**2 - a**2)\n",
    "#             * (epsilon_1**2 - epsilon_0**2)\n",
    "#             / (\n",
    "#                 b**2 * (epsilon_1 + epsilon_0) ** 2\n",
    "#                 - a**2 * (epsilon_1 - epsilon_0) ** 2\n",
    "#             )\n",
    "#             * b**2\n",
    "#             / rho[condition3]\n",
    "#         )\n",
    "#         * E_0\n",
    "#         * torch.cos(phi[condition3])\n",
    "#     )\n",
    "\n",
    "#     return Phi.unsqueeze(-1)\n",
    "\n",
    "\n",
    "# # function that provides the x and y partial derivatives of the (correct) potential, for inputs (x, y)\n",
    "# def synthetic_data_derivatives(inputs, eos=None):\n",
    "#     phi = synthetic_data(inputs)\n",
    "\n",
    "#     # Calculate the derivatives of Phi\n",
    "#     Phi_x = torch.autograd.grad(\n",
    "#         phi,\n",
    "#         inputs,\n",
    "#         grad_outputs=torch.ones_like(phi),\n",
    "#         retain_graph=True,\n",
    "#         create_graph=True,\n",
    "#     )[0][..., 0]\n",
    "#     Phi_y = torch.autograd.grad(\n",
    "#         phi,\n",
    "#         inputs,\n",
    "#         grad_outputs=torch.ones_like(phi),\n",
    "#         retain_graph=True,\n",
    "#         create_graph=True,\n",
    "#     )[0][..., 1]\n",
    "#     return Phi_x, Phi_y\n",
    "\n",
    "\n",
    "# def synthetic_data_bc_derivatives(inputs, eos=None):\n",
    "#     # this version gives \"ideal\" derivatives that are valid at the boundary,\n",
    "#     # pretending the boundary is actually at infinity\n",
    "#     Phi_x = E_0 * torch.ones_like(inputs[..., 0])\n",
    "#     Phi_y = torch.zeros_like(inputs[..., 1])\n",
    "#     return Phi_x, Phi_y\n",
    "\n",
    "\n",
    "# # provide the correct epsilon at the given inputs (x, y)\n",
    "# def true_epsilon(inputs, eos=None):\n",
    "#     x = inputs[..., 0]\n",
    "#     y = inputs[..., 1]\n",
    "\n",
    "#     rho = torch.sqrt(x**2 + y**2)\n",
    "\n",
    "#     # Create conditions for the different regions\n",
    "#     # condition1 = rho < a\n",
    "#     condition2 = (rho >= a) & (rho < b)\n",
    "#     # condition3 = rho >= b\n",
    "\n",
    "#     # Set epsilon for a <= rho < b\n",
    "#     return torch.where(condition2, epsilon_1, epsilon_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The problem consists a cylinder with radius b, centered at the origin, with dielectric constant epsilon_1,\n",
    "# immersed in a medium of dielectric constant epsilon_0; an external field of strength E_0 is applied in the positive x-direction.\n",
    "b = 5.0\n",
    "epsilon_0 = 1.0\n",
    "epsilon_1 = 5.0\n",
    "E_0 = 1.0\n",
    "\n",
    "# The functions below provide the correct electric potential and its derivatives, as well as some other helpful things.\n",
    "# Note that all have a dummy \"eos=None\" argument, because the CV solver framework expects to pass around an equation of state.\n",
    "\n",
    "\n",
    "# function that provides the correct electric potential for inputs (x, y)\n",
    "def synthetic_data(inputs, eos=None):\n",
    "    x = inputs[..., 0]\n",
    "    y = inputs[..., 1]\n",
    "\n",
    "    rho = torch.sqrt(x**2 + y**2)\n",
    "    phi = torch.atan2(y, x)\n",
    "\n",
    "    # Create conditions for the different regions\n",
    "    condition1 = rho < b\n",
    "    condition2 = ~condition1\n",
    "\n",
    "    # Initialize the potential tensor\n",
    "    Phi = torch.zeros_like(rho)\n",
    "\n",
    "    # Calculate Phi for rho < a\n",
    "    Phi[condition1] = (\n",
    "        -2\n",
    "        * (epsilon_0 / (epsilon_0 + epsilon_1))\n",
    "        * E_0\n",
    "        * rho[condition1]\n",
    "        * torch.cos(phi[condition1])\n",
    "    )\n",
    "\n",
    "    # Calculate Phi for a <= rho < b\n",
    "    Phi[condition2] = (\n",
    "        (\n",
    "            -rho[condition2]\n",
    "            + ((epsilon_1 - epsilon_0) / (epsilon_1 + epsilon_0))\n",
    "            * (b**2 / rho[condition2])\n",
    "        )\n",
    "        * E_0\n",
    "        * torch.cos(phi[condition2])\n",
    "    )\n",
    "\n",
    "    return Phi.unsqueeze(-1)\n",
    "\n",
    "\n",
    "# function that provides the x and y partial derivatives of the (correct) potential, for inputs (x, y)\n",
    "def synthetic_data_derivatives(inputs, eos=None):\n",
    "    phi = synthetic_data(inputs)\n",
    "\n",
    "    # Calculate the derivatives of Phi\n",
    "    Phi_x = torch.autograd.grad(\n",
    "        phi,\n",
    "        inputs,\n",
    "        grad_outputs=torch.ones_like(phi),\n",
    "        retain_graph=True,\n",
    "        create_graph=True,\n",
    "    )[0][..., 0]\n",
    "    Phi_y = torch.autograd.grad(\n",
    "        phi,\n",
    "        inputs,\n",
    "        grad_outputs=torch.ones_like(phi),\n",
    "        retain_graph=True,\n",
    "        create_graph=True,\n",
    "    )[0][..., 1]\n",
    "    return Phi_x, Phi_y\n",
    "\n",
    "\n",
    "def synthetic_data_bc_derivatives(inputs, eos=None):\n",
    "    # this version gives \"ideal\" derivatives that are valid at the boundary,\n",
    "    # pretending the boundary is actually at infinity\n",
    "    Phi_x = E_0 * torch.ones_like(inputs[..., 0])\n",
    "    Phi_y = torch.zeros_like(inputs[..., 1])\n",
    "    return Phi_x, Phi_y\n",
    "\n",
    "\n",
    "# provide the correct epsilon at the given inputs (x, y)\n",
    "def true_epsilon(inputs, eos=None):\n",
    "    x = inputs[..., 0]\n",
    "    y = inputs[..., 1]\n",
    "\n",
    "    rho = torch.sqrt(x**2 + y**2)\n",
    "\n",
    "    condition1 = rho < b\n",
    "\n",
    "    # Set epsilon for a <= rho < b\n",
    "    return torch.where(condition1, epsilon_1, epsilon_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correct electric potential\n",
    "\n",
    "x_plt, y_plt, inputs_plt = mesh.get_eval_points()\n",
    "inputs_plt.requires_grad = True\n",
    "Phi_plt = synthetic_data(inputs_plt)\n",
    "Phi_x_plt, Phi_y_plt = synthetic_data_derivatives(inputs_plt)\n",
    "plt.imshow(\n",
    "    Phi_plt.detach().cpu().squeeze().T,\n",
    "    origin=\"lower\",\n",
    "    extent=[x_domain[0], x_domain[1], y_domain[0], y_domain[1]],\n",
    "    cmap=\"viridis\",\n",
    ")\n",
    "plt.colorbar(label=\"Phi\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a visualization of the electric field\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "\n",
    "color = 2 * np.log(\n",
    "    np.hypot(Phi_x_plt.detach().cpu().numpy(), Phi_y_plt.detach().cpu().numpy())\n",
    ")\n",
    "ax.streamplot(\n",
    "    np.linspace(x_domain[0], x_domain[1], Nx_sample - 1),\n",
    "    np.linspace(y_domain[0], y_domain[1], Ny_sample - 1),\n",
    "    -Phi_x_plt.detach().cpu().numpy(),\n",
    "    -Phi_y_plt.detach().cpu().numpy(),\n",
    "    color=color,\n",
    "    linewidth=1,\n",
    "    cmap=plt.cm.inferno,\n",
    "    density=1,\n",
    "    arrowstyle=\"-\",\n",
    "    arrowsize=1.5,\n",
    "    broken_streamlines=True,\n",
    ")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_xlabel(\"x\")\n",
    "ax.set_ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_model = simple_pinn.DirichletPINN(\n",
    "    2,\n",
    "    # [64, 64, 64, 64, 64, 64, 64, 64],\n",
    "    [64, 64, 64, 64],\n",
    "    1,\n",
    "    mesh,\n",
    "    synthetic_data,\n",
    "    None,\n",
    "    activation=torch.nn.Tanh(),\n",
    "    use_bias_in_output_layer=True,\n",
    "    upwind_only=False,\n",
    ").to(DEVICE)\n",
    "# Phi_model.load_state_dict(torch.load(\"Phi_model.pth\"))\n",
    "\n",
    "# epsilon_model = simple_pinn.SegmentationPINN(\n",
    "#     2,\n",
    "#     [64, 64, 64, 64, 64],\n",
    "#     # [32, 32, 32, 32],\n",
    "#     torch.tensor([epsilon_0, epsilon_1]).reshape(2, -1),\n",
    "#     # activation=torch.nn.Tanh(),\n",
    "#     dropout_rate=0.3,\n",
    "# ).to(DEVICE)\n",
    "\n",
    "epsilon_model = simple_pinn.SimplePINN(\n",
    "    2,\n",
    "    [64, 64, 64, 64, 64],\n",
    "    1,\n",
    ").to(DEVICE)\n",
    "\n",
    "model = simple_pinn.CombinedPINN(Phi_model, epsilon_model).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def state_vec_to_fluxes(state_vec, eos, inputs):\n",
    "    epsilon = state_vec[..., 0]\n",
    "    Phi = state_vec[..., 1]\n",
    "    Phi_x = torch.autograd.grad(\n",
    "        Phi, inputs, torch.ones_like(Phi), retain_graph=True, create_graph=True\n",
    "    )[0][..., 0]\n",
    "    Phi_y = torch.autograd.grad(\n",
    "        Phi, inputs, torch.ones_like(Phi), retain_graph=True, create_graph=True\n",
    "    )[0][..., 1]\n",
    "    x = inputs[..., 0]\n",
    "    y = inputs[..., 1]\n",
    "    is_bc = torch.logical_or(\n",
    "        torch.logical_or(x <= x_domain[0], x >= x_domain[1]),\n",
    "        torch.logical_or(y <= y_domain[0], y >= y_domain[1]),\n",
    "    )\n",
    "    Phi_x_bc, Phi_y_bc = synthetic_data_derivatives(inputs)\n",
    "    Phi_x = torch.where(is_bc, Phi_x_bc, Phi_x)\n",
    "    Phi_y = torch.where(is_bc, Phi_y_bc, Phi_y)\n",
    "    epsilon_true = true_epsilon(inputs)\n",
    "    epsilon = torch.where(is_bc, epsilon_true, epsilon)\n",
    "    # F_x = (epsilon * Phi_x).unsqueeze(-1)\n",
    "    # F_y = (epsilon * Phi_y).unsqueeze(-1)\n",
    "    # as a test, just use the correct derivatives everywhere\n",
    "    F_x = (epsilon * Phi_x_bc).unsqueeze(-1)\n",
    "    F_y = (epsilon * Phi_y_bc).unsqueeze(-1)\n",
    "    return F_x, F_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    F_x_eval_points,\n",
    "    F_y_eval_points,\n",
    "    _,\n",
    "    _,\n",
    "    _,\n",
    "    _,\n",
    ") = mesh.get_training_eval_points_and_weights()\n",
    "\n",
    "eval_points = torch.cat(\n",
    "    [F_x_eval_points.reshape(-1, 2), F_y_eval_points.reshape(-1, 2)], dim=0\n",
    ")\n",
    "\n",
    "\n",
    "def model_to_data_comparison(model, eos=None):\n",
    "    deriv_to_phi_weight = 10.0\n",
    "    state_vec = model(eval_points)\n",
    "    epsilon = state_vec[..., 0]\n",
    "    Phi = state_vec[..., 1]\n",
    "    synthetic_data_output = synthetic_data(eval_points, eos)\n",
    "    Phi_x = torch.autograd.grad(\n",
    "        Phi,\n",
    "        eval_points,\n",
    "        torch.ones_like(Phi),\n",
    "        retain_graph=True,\n",
    "        create_graph=True,\n",
    "    )[0][..., 0]\n",
    "    Phi_y = torch.autograd.grad(\n",
    "        Phi,\n",
    "        eval_points,\n",
    "        torch.ones_like(Phi),\n",
    "        retain_graph=True,\n",
    "        create_graph=True,\n",
    "    )[0][..., 1]\n",
    "    synthetic_data_output_x, synthetic_data_output_y = synthetic_data_derivatives(\n",
    "        eval_points, eos\n",
    "    )\n",
    "    model_and_deriv_outputs = torch.cat(\n",
    "        [\n",
    "            Phi,\n",
    "            deriv_to_phi_weight * Phi_x,\n",
    "            deriv_to_phi_weight * Phi_y,\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "    synthetic_data_and_deriv_outputs = torch.cat(\n",
    "        [\n",
    "            synthetic_data_output.squeeze(-1),\n",
    "            deriv_to_phi_weight * synthetic_data_output_x,\n",
    "            deriv_to_phi_weight * synthetic_data_output_y,\n",
    "        ],\n",
    "        dim=-1,\n",
    "    )\n",
    "    return model_and_deriv_outputs, synthetic_data_and_deriv_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "solver = cv_solver.CVSolver(\n",
    "    mesh,\n",
    "    model,\n",
    "    state_vec_to_fluxes,\n",
    "    synthetic_data,\n",
    "    None,\n",
    "    model_to_data_comparison=model_to_data_comparison,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    n_epochs,\n",
    "    lr_Phi,\n",
    "    lr_epsilon,\n",
    "    cv_pde_loss_w,\n",
    "    data_loss_w,\n",
    "    use_scheduler=False,\n",
    "    lr_scheduler=1e-3,\n",
    "):\n",
    "    if lr_epsilon is None:\n",
    "        lr_epsilon = lr_Phi\n",
    "    if use_scheduler:\n",
    "        optimizer = optim.Adam(\n",
    "            chain(Phi_model.parameters(), epsilon_model.parameters()),\n",
    "            lr=lr_scheduler,\n",
    "        )\n",
    "        scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "            optimizer,\n",
    "            patience=100,\n",
    "            factor=0.5,\n",
    "            threshold=1e-3,\n",
    "            min_lr=1e-6,\n",
    "            verbose=True,\n",
    "        )\n",
    "    else:\n",
    "        optimizer = optim.Adam(\n",
    "            [\n",
    "                {\"params\": Phi_model.parameters(), \"lr\": lr_Phi},\n",
    "                {\"params\": epsilon_model.parameters(), \"lr\": lr_epsilon},\n",
    "            ]\n",
    "        )\n",
    "    for epoch in range(n_epochs):\n",
    "        Phi_model.train()\n",
    "        epsilon_model.train()\n",
    "        cv_pde_loss, data_loss = solver.forward()\n",
    "        optimizer.zero_grad()\n",
    "        loss = cv_pde_loss_w * cv_pde_loss + data_loss_w * data_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if use_scheduler:\n",
    "            scheduler.step(loss)\n",
    "        if epoch % 10 == 0 or epoch == n_epochs - 1:\n",
    "            Phi_model.eval()\n",
    "            epsilon_model.eval()\n",
    "            cv_pde_loss, data_loss = solver.forward()\n",
    "            Phi_eval = Phi_model(eval_points).detach().cpu()\n",
    "            epsilon_eval = epsilon_model(eval_points).detach().cpu()\n",
    "            Phi_true = synthetic_data(eval_points).detach().cpu()\n",
    "            epsilon_true = true_epsilon(eval_points).detach().cpu().unsqueeze(-1)\n",
    "            # Calculate the L2 relative error between the true and predicted Phi and epsilon\n",
    "            Phi_error = torch.norm(Phi_eval - Phi_true) / torch.norm(Phi_true)\n",
    "            epsilon_error = torch.norm(epsilon_eval - epsilon_true) / torch.norm(\n",
    "                epsilon_true\n",
    "            )\n",
    "            lr_update_str = (\n",
    "                f\"Current LR: {optimizer.param_groups[0]['lr']:.2e}\"\n",
    "                if use_scheduler\n",
    "                else \"\"\n",
    "            )\n",
    "            print(\n",
    "                f\"Epoch {epoch}: {lr_update_str} \"\n",
    "                f\"PDE loss: {cv_pde_loss.item():.10e}\"\n",
    "                f\" Data loss: {data_loss.item():.3e}\"\n",
    "                f\" Phi error: {Phi_error.item():.3e}\"\n",
    "                f\" epsilon error: {epsilon_error.item():.3e}\"\n",
    "                f\" argmax: {torch.abs(solver.cv_pde_loss_structure).argmax().item()}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(\n",
    "    1000,\n",
    "    lr_Phi=0,\n",
    "    lr_epsilon=1e-3,\n",
    "    cv_pde_loss_w=1.0,\n",
    "    data_loss_w=0.0,\n",
    "    use_scheduler=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_model.eval()\n",
    "epsilon_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(Phi_model.state_dict(), \"Phi_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(solver.cv_pde_loss_structure.detach().cpu().squeeze().T, cmap=\"viridis\")\n",
    "plt.colorbar(label=\"Loss\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_epsilon_grid(e_model, epoch):\n",
    "    x, y, inputs = mesh.get_eval_points()\n",
    "    e_grid = e_model(inputs).detach().cpu()\n",
    "    e_gt = true_epsilon(inputs).detach().cpu().unsqueeze(-1)\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    im1 = ax1.imshow(\n",
    "        e_grid.squeeze().T,\n",
    "        origin=\"lower\",\n",
    "        extent=[x_domain[0], x_domain[1], y_domain[0], y_domain[1]],\n",
    "        cmap=\"viridis\",\n",
    "    )\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "    ax1.set_title(f\"e_grid (Epoch {epoch})\")\n",
    "    # ax1.set_xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "\n",
    "    # im2 = ax2.imshow(\n",
    "    #     e_gt.squeeze().T,\n",
    "    #     origin=\"lower\",\n",
    "    #     extent=[x_domain[0], x_domain[1], y_domain[0], y_domain[1]],\n",
    "    #     cmap=\"viridis\",\n",
    "    # )\n",
    "    # ax2.set_xlabel(\"x\")\n",
    "    # # ax2.set_ylabel(\"y\")\n",
    "    # ax2.set_title(f\"e_gt (Epoch {epoch})\")\n",
    "    # # ax2.set_xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "\n",
    "    # Create a shared colorbar\n",
    "    # cbar = fig.colorbar(im2, ax=[ax1, ax2], label=\"e_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_u_grid(u_model, epoch):\n",
    "    x, y, inputs = mesh.get_eval_points()\n",
    "    u_grid = u_model(inputs).detach().cpu()\n",
    "    u_gt = synthetic_data(inputs).detach().cpu()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    im1 = ax1.imshow(\n",
    "        u_grid.squeeze().T,\n",
    "        origin=\"lower\",\n",
    "        extent=[x_domain[0], x_domain[1], y_domain[0], y_domain[1]],\n",
    "        cmap=\"viridis\",\n",
    "    )\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "    ax1.set_title(f\"u_grid (Epoch {epoch})\")\n",
    "    # ax1.set_xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "\n",
    "    im2 = ax2.imshow(\n",
    "        u_gt.squeeze().T,\n",
    "        origin=\"lower\",\n",
    "        extent=[x_domain[0], x_domain[1], y_domain[0], y_domain[1]],\n",
    "        cmap=\"viridis\",\n",
    "    )\n",
    "    ax2.set_xlabel(\"x\")\n",
    "    # ax2.set_ylabel(\"y\")\n",
    "    ax2.set_title(f\"u_gt (Epoch {epoch})\")\n",
    "    # ax2.set_xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "\n",
    "    # Create a shared colorbar\n",
    "    cbar = fig.colorbar(im2, ax=[ax1, ax2], label=\"u_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y, inputs = mesh.get_eval_points()\n",
    "plot_u_grid(Phi_model, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_epsilon_grid(epsilon_model, -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
