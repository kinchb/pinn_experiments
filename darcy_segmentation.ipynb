{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.optim\n",
    "import simple_pinn\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from pyrecorder.recorder import Recorder\n",
    "from pyrecorder.writers.video import Video\n",
    "from pyrecorder.converters.matplotlib import Matplotlib\n",
    "from itertools import chain\n",
    "import time\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_domain = y_domain = [0, 1]\n",
    "Nx_sample = Ny_sample = 100\n",
    "x = torch.linspace(x_domain[0], x_domain[1], Nx_sample, requires_grad=True).to(DEVICE)\n",
    "y = torch.linspace(y_domain[0], y_domain[1], Ny_sample, requires_grad=True).to(DEVICE)\n",
    "X, Y = torch.meshgrid(x, y, indexing=\"ij\")\n",
    "inputs = torch.stack((X, Y), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_0 = 1.0\n",
    "K_1 = 10.0\n",
    "\n",
    "\n",
    "def synthetic_data(inputs):\n",
    "    u = torch.sin(2.0 * torch.pi * inputs[..., 0]) * torch.sin(\n",
    "        2.0 * torch.pi * inputs[..., 1]\n",
    "    )\n",
    "    return u.unsqueeze(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_model = simple_pinn.SimplePINN(\n",
    "    2,\n",
    "    # [64, 64, 64, 64, 64, 64, 64, 64],\n",
    "    [32, 32, 32, 32],\n",
    "    1,\n",
    "    activation=torch.nn.Tanh(),\n",
    "    # use_bias_in_output_layer=True,\n",
    ").to(DEVICE)\n",
    "\n",
    "K_model = simple_pinn.SegmentationPINN(\n",
    "    2,\n",
    "    # [64, 64, 64, 64, 64, 64, 64, 64],\n",
    "    [32, 32, 32, 32],\n",
    "    torch.tensor([K_0, K_1]).reshape(2, -1),\n",
    "    # activation=torch.nn.Tanh(),\n",
    ").to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_bulk_loss(u_model, K_model, inputs):\n",
    "    u = u_model(inputs)\n",
    "    K = K_model(inputs)\n",
    "    u_x = torch.autograd.grad(\n",
    "        u, inputs, torch.ones_like(u), retain_graph=True, create_graph=True\n",
    "    )[0][..., 0]\n",
    "    u_y = torch.autograd.grad(\n",
    "        u, inputs, torch.ones_like(u), retain_graph=True, create_graph=True\n",
    "    )[0][..., 1]\n",
    "    d_kux_dx = torch.autograd.grad(\n",
    "        u_x,\n",
    "        inputs,\n",
    "        torch.ones_like(u_x),\n",
    "        retain_graph=True,\n",
    "        create_graph=True,\n",
    "    )[0][..., 0]\n",
    "    d_kuy_dy = torch.autograd.grad(\n",
    "        u_y,\n",
    "        inputs,\n",
    "        torch.ones_like(u_y),\n",
    "        retain_graph=True,\n",
    "        create_graph=True,\n",
    "    )[0][..., 1]\n",
    "    rhs = (\n",
    "        8.0\n",
    "        * torch.pi**2\n",
    "        * torch.where(\n",
    "            inputs[..., 0] < 0.25,\n",
    "            K_0,\n",
    "            K_1,\n",
    "        )\n",
    "        * torch.sin(2.0 * torch.pi * inputs[..., 0])\n",
    "        * torch.sin(2.0 * torch.pi * inputs[..., 1])\n",
    "    )\n",
    "    return torch.mean(torch.square(K.squeeze() * (d_kux_dx + d_kuy_dy) + rhs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# impose Dirichlet boundary conditions on all boundaries\n",
    "def eval_bc_loss(model, inputs):\n",
    "    # bottom_boundary = inputs[0, :, :]\n",
    "    # top_boundary = inputs[-1, :, :]\n",
    "    # left_boundary = inputs[:, 0, :]\n",
    "    # right_boundary = inputs[:, -1, :]\n",
    "    # u_bottom = model(bottom_boundary)\n",
    "    # u_top = model(top_boundary)\n",
    "    # u_left = model(left_boundary)\n",
    "    # u_right = model(right_boundary)\n",
    "    # u_bc = torch.zeros_like(u_bottom)\n",
    "    # return (\n",
    "    #     torch.mean(torch.square(u_bottom - u_bc))\n",
    "    #     + torch.mean(torch.square(u_top - u_bc))\n",
    "    #     + torch.mean(torch.square(u_left - u_bc))\n",
    "    #     + torch.mean(torch.square(u_right - u_bc))\n",
    "    # )\n",
    "    u_model = model(inputs)\n",
    "    return torch.mean(torch.square(u_model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_data_loss(u_model, K_model, inputs):\n",
    "    u = u_model(inputs)\n",
    "    u_gt = synthetic_data(inputs)\n",
    "    return torch.mean(torch.square(u - u_gt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_K_grid(K_grid, epoch):\n",
    "    plt.imshow(\n",
    "        K_grid.squeeze().T,\n",
    "        origin=\"lower\",\n",
    "        extent=[x_domain[0], x_domain[1], y_domain[0], y_domain[1]],\n",
    "        cmap=\"viridis\",\n",
    "        vmin=K_0,\n",
    "        vmax=K_1,\n",
    "    )\n",
    "    plt.colorbar(label=\"K_grid\")\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(f\"K_grid (Epoch {epoch})\")\n",
    "    plt.xticks([0, 0.25, 0.5, 0.75, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_u_grid(u_model, epoch):\n",
    "    u_grid = u_model(inputs).detach().cpu()\n",
    "    u_gt = synthetic_data(inputs).detach().cpu()\n",
    "\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    im1 = ax1.imshow(\n",
    "        u_grid.squeeze().T,\n",
    "        origin=\"lower\",\n",
    "        extent=[x_domain[0], x_domain[1], y_domain[0], y_domain[1]],\n",
    "        cmap=\"viridis\",\n",
    "    )\n",
    "    ax1.set_xlabel(\"x\")\n",
    "    ax1.set_ylabel(\"y\")\n",
    "    ax1.set_title(f\"u_grid (Epoch {epoch})\")\n",
    "    ax1.set_xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "\n",
    "    im2 = ax2.imshow(\n",
    "        u_gt.squeeze().T,\n",
    "        origin=\"lower\",\n",
    "        extent=[x_domain[0], x_domain[1], y_domain[0], y_domain[1]],\n",
    "        cmap=\"viridis\",\n",
    "    )\n",
    "    ax2.set_xlabel(\"x\")\n",
    "    ax2.set_ylabel(\"y\")\n",
    "    ax2.set_title(f\"u_gt (Epoch {epoch})\")\n",
    "    ax2.set_xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "\n",
    "    # Create a shared colorbar\n",
    "    cbar = fig.colorbar(im2, ax=[ax1, ax2], label=\"u_grid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_error_grid(u_model, epoch):\n",
    "    u_grid = u_model(inputs).detach().cpu()\n",
    "    u_gt = synthetic_data(inputs).detach().cpu()\n",
    "\n",
    "    relative_error = torch.norm(u_grid - u_gt, p=2, dim=-1) / torch.norm(\n",
    "        u_gt, p=2, dim=-1\n",
    "    )\n",
    "\n",
    "    plt.imshow(\n",
    "        relative_error.squeeze().T,\n",
    "        origin=\"lower\",\n",
    "        extent=[x_domain[0], x_domain[1], y_domain[0], y_domain[1]],\n",
    "        cmap=\"viridis\",\n",
    "    )\n",
    "    plt.xlabel(\"x\")\n",
    "    plt.ylabel(\"y\")\n",
    "    plt.title(f\"Relative Error (Epoch {epoch})\")\n",
    "    plt.xticks([0, 0.25, 0.5, 0.75, 1])\n",
    "    plt.colorbar(label=\"Relative Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bulk_loss_history = []\n",
    "bc_loss_history = []\n",
    "data_loss_history = []\n",
    "total_loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# note this is so simple in part because we're solving a problem on the unit square\n",
    "def sample_bulk_inputs(N):\n",
    "    randomly_sampled_bulk_inputs = torch.rand(N, N, 2, requires_grad=True).to(DEVICE)\n",
    "    return randomly_sampled_bulk_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_bc_inputs(N):\n",
    "    lower_bc_inputs = torch.stack([torch.rand(N), torch.zeros(N)], dim=-1).to(DEVICE)\n",
    "    upper_bc_inputs = torch.stack([torch.rand(N), torch.ones(N)], dim=-1).to(DEVICE)\n",
    "    left_bc_inputs = torch.stack([torch.zeros(N), torch.rand(N)], dim=-1).to(DEVICE)\n",
    "    right_bc_inputs = torch.stack([torch.ones(N), torch.rand(N)], dim=-1).to(DEVICE)\n",
    "    bc_inputs = torch.cat(\n",
    "        [lower_bc_inputs, upper_bc_inputs, left_bc_inputs, right_bc_inputs]\n",
    "    )\n",
    "    bc_inputs.requires_grad = True\n",
    "    return bc_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assemble_bc_inputs(inputs):\n",
    "    lower_bc_inputs = inputs[0, :, :]\n",
    "    upper_bc_inputs = inputs[-1, :, :]\n",
    "    left_bc_inputs = inputs[:, 0, :]\n",
    "    right_bc_inputs = inputs[:, -1, :]\n",
    "    return torch.cat(\n",
    "        [lower_bc_inputs, upper_bc_inputs, left_bc_inputs, right_bc_inputs]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# u_model_lr = 1e-5\n",
    "# K_model_lr = 1e-4\n",
    "\n",
    "# u_model_params = u_model.parameters()\n",
    "# K_model_params = K_model.parameters()\n",
    "\n",
    "# optimizer = torch.optim.Adam(\n",
    "#     [\n",
    "#         {\"params\": u_model_params, \"lr\": u_model_lr},\n",
    "#         # {\"params\": K_model_params, \"lr\": K_model_lr},\n",
    "#     ]\n",
    "# )\n",
    "\n",
    "# # optimizer = torch.optim.LBFGS(\n",
    "# #     u_model.parameters(), lr=0.01, max_iter=20, line_search_fn=\"strong_wolfe\"\n",
    "# # )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bulk_inputs = sample_bulk_inputs(100)\n",
    "# bc_inputs = sample_bc_inputs(100)\n",
    "\n",
    "bulk_inputs = inputs\n",
    "bc_inputs = assemble_bc_inputs(inputs)\n",
    "\n",
    "\n",
    "def closure():\n",
    "    optimizer.zero_grad()\n",
    "    bulk_loss = eval_bulk_loss(u_model, K_model, bulk_inputs)\n",
    "    bc_loss = eval_bc_loss(u_model, bc_inputs)\n",
    "    data_loss = eval_data_loss(u_model, K_model, inputs)\n",
    "    total_loss = bulk_loss + bc_loss + data_loss\n",
    "    total_loss.backward()\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainModel:\n",
    "    def __init__(self, record=False):\n",
    "        self.epochs_total = 0\n",
    "        self.record = record\n",
    "\n",
    "    def train(self, n_epochs, lr_u, lr_K=None):\n",
    "        if lr_K is None:\n",
    "            lr_K = lr_u\n",
    "            optimizer = torch.optim.Adam(\n",
    "                [\n",
    "                    {\"params\": u_model.parameters(), \"lr\": lr_u},\n",
    "                    {\"params\": K_model.parameters(), \"lr\": lr_K},\n",
    "                ]\n",
    "            )\n",
    "\n",
    "        for n in range(n_epochs):\n",
    "            bulk_loss = eval_bulk_loss(u_model, K_model, bulk_inputs)\n",
    "            bc_loss = eval_bc_loss(u_model, bc_inputs)\n",
    "            data_loss = eval_data_loss(u_model, K_model, inputs)\n",
    "            total_loss = bulk_loss + bc_loss  # + data_loss\n",
    "            bulk_loss_history.append(bulk_loss.item())\n",
    "            bc_loss_history.append(bc_loss.item())\n",
    "            data_loss_history.append(data_loss.item())\n",
    "            total_loss_history.append(total_loss.item())\n",
    "            optimizer.zero_grad()\n",
    "            total_loss.backward()\n",
    "            optimizer.step()\n",
    "            if n % 10 == 0:\n",
    "                print(\n",
    "                    f\"lr = {lr_u}, {lr_K}; Epoch {n}: Total Loss = {total_loss.item():.4e}, Bulk Loss = {bulk_loss.item():.4e}, BC Loss = {bc_loss.item():.4e}, Data Loss = {data_loss.item():.4e}\"\n",
    "                )\n",
    "                K_grid = K_model(inputs).detach().cpu()\n",
    "                if self.record:\n",
    "                    plot_K_grid(K_grid, self.epochs_total)\n",
    "                    rec.record()\n",
    "                    time.sleep(0.1)\n",
    "            self.epochs_total += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model = TrainModel(record=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = Matplotlib(dpi=120)\n",
    "writer = Video(\"K_training_v2.mp4\", fps=24)\n",
    "with Recorder(writer) as rec:\n",
    "    train_model.train(5000, 1e-2)\n",
    "    train_model.train(10_000, 1e-3)\n",
    "    train_model.train(10_000, 1e-4)\n",
    "    train_model.train(20_000, 1e-5)\n",
    "    train_model.train(20_000, 1e-6)\n",
    "    train_model.train(20_000, 1e-7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100_000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converter = Matplotlib(dpi=120)\n",
    "# writer = Video(\"K_training.mp4\", fps=24)\n",
    "\n",
    "# n_epochs = 20_000\n",
    "\n",
    "# bulk_inputs = sample_bulk_inputs(100)\n",
    "# bc_inputs = sample_bc_inputs(100)\n",
    "\n",
    "# with Recorder(writer) as rec:\n",
    "#     for n in range(n_epochs):\n",
    "#         optimizer.zero_grad()\n",
    "#         bulk_loss = eval_bulk_loss(u_model, K_model, bulk_inputs)\n",
    "#         bc_loss = eval_bc_loss(u_model, bc_inputs)\n",
    "#         total_loss = bulk_loss + bc_loss\n",
    "#         bulk_loss_history.append(bulk_loss.item())\n",
    "#         bc_loss_history.append(bc_loss.item())\n",
    "#         total_loss_history.append(total_loss.item())\n",
    "#         total_loss.backward()\n",
    "#         optimizer.step()\n",
    "#         if n % 100 == 0:\n",
    "#             print(\n",
    "#                 f\"Epoch {n}: Total Loss = {total_loss.item():.4e}, Bulk Loss = {bulk_loss.item():.4e}, BC Loss = {bc_loss.item():.4e}\"\n",
    "#             )\n",
    "#             bulk_inputs = sample_bulk_inputs(100)\n",
    "#             bc_inputs = sample_bc_inputs(100)\n",
    "#             K_grid = K_model(inputs).detach().cpu()\n",
    "#             # plot_K_grid(K_grid, n)\n",
    "#             # rec.record()\n",
    "#             # time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# Plot the loss history components\n",
    "plt.plot(bulk_loss_history, label=\"Bulk Loss\")\n",
    "plt.plot(bc_loss_history, label=\"BC Loss\")\n",
    "plt.plot(data_loss_history, label=\"Data Loss\")\n",
    "\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.title(\"Loss History Components\")\n",
    "plt.loglog()\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "K_grid = K_model(inputs).detach().cpu()\n",
    "plot_K_grid(K_grid, n_epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_u_grid(u_model, n_epochs)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_error_grid(u_model, n_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the y values for sampling\n",
    "y_values = np.linspace(y_domain[0], y_domain[1], 10)\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Define a color map for assigning colors to y values\n",
    "color_map = matplotlib.colormaps.get_cmap(\"tab10\")\n",
    "\n",
    "# Iterate over the y values and evaluate the model and synthetic data\n",
    "for i, y in enumerate(y_values):\n",
    "    # Create a tensor with the x values\n",
    "    x_values = torch.linspace(x_domain[0], x_domain[1], 100)\n",
    "\n",
    "    # Create the inputs tensor\n",
    "    plt_inputs = torch.stack((x_values, torch.full_like(x_values, y)), dim=-1).to(\n",
    "        DEVICE\n",
    "    )\n",
    "\n",
    "    # Evaluate the model and synthetic data\n",
    "    u_model_output = u_model(plt_inputs).detach().cpu().numpy()\n",
    "    synthetic_data_output = synthetic_data(plt_inputs).detach().cpu().numpy()\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append(\n",
    "        (x_values.numpy(), u_model_output.squeeze(), synthetic_data_output.squeeze(), y)\n",
    "    )\n",
    "\n",
    "# Plot the results\n",
    "for i, (x_values, u_model_output, synthetic_data_output, y) in enumerate(results):\n",
    "    color = color_map(i % color_map.N)  # Assign a unique color to each y value\n",
    "    plt.plot(x_values, u_model_output, label=f\"u_model (y={y:.2f})\", color=color)\n",
    "    plt.plot(\n",
    "        x_values,\n",
    "        synthetic_data_output,\n",
    "        label=f\"synthetic_data (y={y:.2f})\",\n",
    "        linestyle=\"--\",\n",
    "        color=color,\n",
    "    )\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"Output\")\n",
    "plt.title(\"Comparison of u_model and synthetic data\")\n",
    "\n",
    "# Place the legend outside the plot\n",
    "plt.legend(bbox_to_anchor=(1.05, 1), loc=\"upper left\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the y values for sampling\n",
    "y_values = np.linspace(y_domain[0], y_domain[1], 10)\n",
    "\n",
    "# Initialize an empty list to store the results\n",
    "results = []\n",
    "\n",
    "# Define a color map for assigning colors to y values\n",
    "color_map = matplotlib.colormaps.get_cmap(\"tab10\")\n",
    "\n",
    "# Iterate over the y values and evaluate the model and synthetic data\n",
    "for i, y in enumerate(y_values):\n",
    "    # Create a tensor with the x values\n",
    "    x_values = torch.linspace(x_domain[0], x_domain[1], 100)\n",
    "\n",
    "    # Create the inputs tensor\n",
    "    plt_inputs = torch.stack((x_values, torch.full_like(x_values, y)), dim=-1).to(\n",
    "        DEVICE\n",
    "    )\n",
    "\n",
    "    # Evaluate the model and synthetic data\n",
    "    K_grid_output = K_model(plt_inputs).detach().cpu().numpy()\n",
    "\n",
    "    # Append the results to the list\n",
    "    results.append((x_values.numpy(), K_grid_output.squeeze(), y))\n",
    "\n",
    "# Plot the results\n",
    "for i, (x_values, K_grid_output, y) in enumerate(results):\n",
    "    color = color_map(i % color_map.N)  # Assign a unique color to each y value\n",
    "    plt.plot(x_values, K_grid_output, label=f\"y={y:.2f}\", color=color)\n",
    "\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"K_grid\")\n",
    "plt.title(\"K_grid as a function of x for various y\")\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pinns",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
